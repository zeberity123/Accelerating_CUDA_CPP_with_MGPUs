{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#65AE11;\">Memory Copies in Non-Default Streams</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section you will perform host-to-device and device-to-host memory transfers in non-default streams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#65AE11;\">Objectives</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the time you complete this section you will:\n",
    "\n",
    "* Know how to create pinned memory, which can be asynchronously transfered in non-default streams\n",
    "* Be able to perform host-to-device memory transfers in non-default streams\n",
    "* Be able to perform device-to-host memory transfers in non-default streams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#65AE11;\">Allocating Pinned Memory</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to asynchronously copy data, CUDA needs to make assumptions about its location. Typical host memory uses [paging](https://en.wikipedia.org/wiki/Paging) so that in addition to RAM, data can be stored on some backup storage device like a physical disk.\n",
    "\n",
    "Pinning, or page-locking memory bypasses host OS paging, storing allocated memory in RAM. Page-locking, or pinning memory is required to transfer memory asynchronously in a non-default stream.\n",
    "\n",
    "Because it prevents storage of data on some backup storage, pinned memory is a limited resource, and care must be taken not to over use it.\n",
    "\n",
    "Pinned host memory is allocated with `cudaMallocHost`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```c\n",
    "const uint64_t num_entries = 1UL << 26;\n",
    "uint64_t *data_cpu;\n",
    "cudaMallocHost(&data_cpu, sizeof(uint64_t)*num_entries);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#65AE11;\">Host-to-Device Memory Transfers in a Non-Default Stream</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pinned host memory can be transfered to GPU memory in a non-default stream using `cudaMemcpyAsync` which is similar to `cudaMemcpy` but expects a 5th stream identifier argument:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```c\n",
    "cudaStream_t stream;\n",
    "cudaStreamCreate(&stream);\n",
    "\n",
    "const uint64_t num_entries = 1UL << 26;\n",
    "\n",
    "uint64_t *data_cpu, *data_gpu;\n",
    "\n",
    "cudaMallocHost(&data_cpu, sizeof(uint64_t)*num_entries);\n",
    "cudaMalloc(&data_cpu, sizeof(uint64_t)*num_entries);\n",
    "\n",
    "cudaMemcpyAsync(data_gpu, \n",
    "                data_cpu, \n",
    "                sizeof(uint64_t)*num_entries, \n",
    "                cudaMemcpyHostToDevice, \n",
    "                stream);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#65AE11;\">Device-to-Host Memory Transfers in a Non-Default Stream</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU memory can be also be transfered to pinned host memory in a non-default stream using `cudaMemcpyAsync`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```c\n",
    "// Assume data is already present on the GPU, and that `data_cpu` is pinned.\n",
    "\n",
    "cudaMemcpyAsync(data_cpu, \n",
    "                data_gpu, \n",
    "                sizeof(uint64_t)*num_entries, \n",
    "                cudaMemcpyDeviceToHost, \n",
    "                stream);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As is the case with all modern GPUs, GPU devices with 2 or more copy engines can perform host-to-device and device-to-host memory transfers in different non-default streams at the same time. You will do this yourself later in the course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#65AE11;\">Stream Synchronization</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `cudaStreamSynchronize` will cause host code to block until a given stream has completed its operations. Stream synchronization should be used when guarantees are needed about the completion of a stream's work, for example, when host code needs to wait for asynchronous memory transfers in a non-default stream to complete:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```c\n",
    "// Assume data is already present on the GPU, and that `data_cpu` is pinned.\n",
    "\n",
    "cudaMemcpyAsync(data_cpu, \n",
    "                data_gpu, \n",
    "                sizeof(uint64_t)*num_entries, \n",
    "                cudaMemcpyDeviceToHost, \n",
    "                stream);\n",
    "\n",
    "// Block until work (in this case memory transfer to host) in `stream` is complete.\n",
    "cudaStreamSynchronize(stream);\n",
    "\n",
    "// `data_cpu` transfer to host via `stream` is now guaranteed to be complete.\n",
    "checkResultCpu(data_cpu);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#65AE11;\">Exercise: Perform Memory Transfers in Non-Default Stream</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open and refactor [*07_Memcpy_in_Streams/baseline_cipher/baseline.cu*](baseline_cipher/baseline.cu) to perform both host-to-device and device-to-host memory transfers in a non-default stream.\n",
    "\n",
    "Generate a report file for the refactored application by using a JupyterLab terminal and running `make profile` from within the *07_Memcpy_in_Streams/baseline_cipher* directory. (See the [*Makefile*](baseline_cipher/Makefile) there for details).\n",
    "\n",
    "Open the report file in Nsight Systems. If you've closed the Nsight Systems tab, you can reopen it by following the instructions in [*Nsight Systems Setup*](../04_Nsight_Systems_Setup/Nsight_Systems_Setup.ipynb). As a reminder the password is `nvidia`.\n",
    "\n",
    "If you were successful, you should notice in the Nsight Systems visual timeline that memory transfers are now occuring in non-default streams, as is shown in the screenshot below.\n",
    "\n",
    "If you get stuck, please refer to [07_Memcpy_in_Streams/baseline_cipher/baseline_solution.cu](../07_Memcpy_in_Streams/baseline_cipher/baseline_solution.cu)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![memcpy_in_stream](images/memcpy_in_stream.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#65AE11;\">Check for Understanding</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please answer the following to confirm you've learned the main objectives of this section. You can display the answers for each question by clicking on the \"...\" cells below the questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Knowing what you do about default stream behavior, explain why in the exercise above (and as shown in the screenshot above) we did not see any overlap between memory transfers and kernel execution, or, between host-to-device and device-to-host memory transfers, even though memory transfers were performed in non-default streams.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "**Answer:**\n",
    "\n",
    "Commands issued into the default stream will wait until all other non-default stream commands have completed, and, will block any other non-default streams from doing work until it completes.\n",
    "\n",
    "In the above exercise, because we did not specify a non-default stream, the kernel launch `decrypt_gpu` occured in the default stream. Therefore, it waited for the host-to-device memory transfers in the non-default stream to complete before beginning, and then, blocked the device-to-host memory transfers from beginning until it completed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Memory allocated on the host with `malloc` can be transfered asynchronously with `cudaMemcpyAsync`?**\n",
    "\n",
    "1. True\n",
    "2. False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "**Answer: 2.**\n",
    "\n",
    "Host OS memory paging, cannot guarantee the immediate location of any memory in RAM, but rather, might use paging so that the memory can be stored outside of RAM.\n",
    "\n",
    "In order to transfer memory to or from the host asynchronously in a non-default stream, memory must be page-locked or pinned. To do this, we use `cudaMallocHost` and not `malloc`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Host code that uses data being transfered in a non-default stream will wait for memory transfers to complete before beginning work.**\n",
    "\n",
    "1. True\n",
    "2. False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "**Answer: 2.**\n",
    "\n",
    "`cudaStreamSynchronize` must be used to block host code from proceeding until work in a given stream is complete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#65AE11;\">Next</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While you have learned how to perform kernel launches and memory transfers in non-default streams, the last 2 sections have not actually resulted in performance gains for the cipher application.\n",
    "\n",
    "In the next sections, you will learn how to perform copy/compute overlap, and will begin to see actual performance gains from using concurrent streams.\n",
    "\n",
    "Please continue to the next section: [*Copy Compute Considerations*](../08_Copy_Compute_Considerations/Copy_Compute_Considerations.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#65AE11;\">Optional Further Study</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are for students with time and interest to do additional study on topics related to this workshop.\n",
    "\n",
    "* The `async` suffix for some memcpy operations \"is a misnomer as each function may exhibit synchronous or asynchronous behavior depending on the arguments passed to the function.\" See [the CUDA Runtime Docs](https://docs.nvidia.com/cuda/cuda-runtime-api/api-sync-behavior.html#api-sync-behavior) for more details.\n",
    "* For those of you working with applications utilizing unified memory, see the answer to [this Stack Overflow answer](https://stackoverflow.com/questions/23518299/unified-memory-and-streams-in-c) (including its references to [the docs](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#um-coherency-hd) for details."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
